#!/usr/bin/env python

"""
Camera sensors and camera management implementation.
"""

import weakref
import math
import carla
from carla import ColorConverter as cc
import numpy as np
import pygame


class CameraManager(object):
    """Camera manager for handling multiple camera sensors."""

    def __init__(self, parent_actor, hud, gamma_correction):
        self.sensor = None
        self.surface = None
        self._parent = parent_actor
        self.hud = hud
        self.recording = False
        bound_x = 0.5 + self._parent.bounding_box.extent.x
        bound_y = 0.5 + self._parent.bounding_box.extent.y
        bound_z = 0.5 + self._parent.bounding_box.extent.z
        Attachment = carla.AttachmentType

        if not self._parent.type_id.startswith("walker.pedestrian"):
            self._camera_transforms = [
                (carla.Transform(carla.Location(x=-2.0*bound_x, y=+0.0*bound_y, z=2.0*bound_z), carla.Rotation(pitch=8.0)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=+0.8*bound_x, y=+0.0*bound_y, z=1.3*bound_z)), Attachment.Rigid),
                (carla.Transform(carla.Location(x=+1.9*bound_x, y=+1.0*bound_y, z=1.2*bound_z)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=-2.8*bound_x, y=+0.0*bound_y, z=4.6*bound_z), carla.Rotation(pitch=6.0)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=-1.0, y=-1.0*bound_y, z=0.4*bound_z)), Attachment.Rigid)]
        else:
            self._camera_transforms = [
                (carla.Transform(carla.Location(x=-2.5, z=0.0), carla.Rotation(pitch=-8.0)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=1.6, z=1.7)), Attachment.Rigid),
                (carla.Transform(carla.Location(x=2.5, y=0.5, z=0.0), carla.Rotation(pitch=-8.0)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=-4.0, z=2.0), carla.Rotation(pitch=6.0)), Attachment.SpringArmGhost),
                (carla.Transform(carla.Location(x=0, y=-2.5, z=-0.0), carla.Rotation(yaw=90.0)), Attachment.Rigid)]

        self.transform_index = 1
        self.sensors = [
            ['sensor.camera.rgb',                   cc.Raw, 'Camera RGB',                                'front_camera',{}],
            ['sensor.camera.depth',                 cc.Raw, 'Camera Depth (Raw)',                        'depth_front', {}],
            ['sensor.camera.depth',                 cc.Depth, 'Camera Depth (Gray Scale)',               'depth_front', {}],
            ['sensor.camera.depth',                 cc.LogarithmicDepth, 'Camera Depth (Log Gray Scale)','depth_front', {}],
            ['sensor.camera.semantic_segmentation', cc.Raw, 'Camera Semantic (Raw)',                     'sem_front',   {}],
            ['sensor.camera.semantic_segmentation', cc.CityScapesPalette, 'Camera Semantic (CityScapes)','sem_front',   {}],
            ['sensor.camera.instance_segmentation', cc.CityScapesPalette, 'Instance Seg (CityScapes)',   'inst_front',  {}],
            ['sensor.camera.instance_segmentation', cc.Raw, 'Instance Seg (Raw)',                        'inst_front',  {}],
            ['sensor.lidar.ray_cast',               None,   'Lidar (Ray-Cast)',                          'roof_lidar',  {'range':'50'}],
            ['sensor.camera.dvs',                   cc.Raw, 'Dynamic Vision Sensor',                     'dvs_front',   {}],
            ['sensor.camera.rgb',                   cc.Raw, 'Camera RGB Distorted',                      'rgb_front2',  {
                'lens_circle_multiplier':'3.0',
                'lens_circle_falloff':'3.0',
                'chromatic_aberration_intensity':'0.5',
                'chromatic_aberration_offset':'0'
            }],
            ['sensor.camera.optical_flow',          cc.Raw, 'Optical Flow',                              'flow_front',  {}],
            ['sensor.camera.normals',               cc.Raw, 'Camera Normals',                            'norm_front',  {}],
        ]
        world = self._parent.get_world()
        bp_library = world.get_blueprint_library()
        for item in self.sensors:
            bp = bp_library.find(item[0])
            if bp.has_attribute('role_name'):
                bp.set_attribute('role_name', item[3])

            attrs = item[4] if len(item) > 4 else {}
            if item[0].startswith('sensor.camera'):
                bp.set_attribute('image_size_x', str(hud.dim[0]))
                bp.set_attribute('image_size_y', str(hud.dim[1]))
                if bp.has_attribute('gamma'):
                    bp.set_attribute('gamma', str(gamma_correction))
                for k, v in attrs.items():
                    bp.set_attribute(k, v)
            elif item[0].startswith('sensor.lidar'):
                self.lidar_range = 50
                for k, v in attrs.items():
                    bp.set_attribute(k, v)
                    if k == 'range':
                        self.lidar_range = float(v)

            item.append(bp)
        self.index = None

    def toggle_camera(self):
        """Switch to next camera position."""
        self.transform_index = (self.transform_index + 1) % len(self._camera_transforms)
        self.set_sensor(self.index, notify=False, force_respawn=True)

    def set_sensor(self, index, notify=True, force_respawn=False):
        """Set active sensor."""
        index = index % len(self.sensors)
        needs_respawn = True if self.index is None else \
            (force_respawn or (self.sensors[index][2] != self.sensors[self.index][2]))
        if needs_respawn:
            if self.sensor is not None:
                self.sensor.destroy()
                self.surface = None
            self.sensor = self._parent.get_world().spawn_actor(
                self.sensors[index][-1],
                self._camera_transforms[self.transform_index][0],
                attach_to=self._parent,
                attachment_type=self._camera_transforms[self.transform_index][1])
            # We need to pass the lambda a weak reference to self to avoid circular reference
            weak_self = weakref.ref(self)
            self.sensor.listen(lambda image: CameraManager._parse_image(weak_self, image))
        if notify:
            self.hud.notification(self.sensors[index][2])
        self.index = index

    def next_sensor(self):
        """Switch to next sensor."""
        self.set_sensor(self.index + 1)

    def toggle_recording(self):
        """Toggle camera recording."""
        self.recording = not self.recording
        self.hud.notification('Recording %s' % ('On' if self.recording else 'Off'))

    def render(self, display):
        """Render camera feed."""
        if self.surface is not None:
            display.blit(self.surface, (0, 0))

    def destroy(self):
        """Clean up camera."""
        if self.sensor is not None:
            self.sensor.destroy()
            self.sensor = None

    @staticmethod
    def _parse_image(weak_self, image):
        """Parse and convert camera image data."""
        self = weak_self()
        if not self:
            return
        if self.sensors[self.index][0].startswith('sensor.lidar'):
            points = np.frombuffer(image.raw_data, dtype=np.dtype('f4'))
            points = np.reshape(points, (int(points.shape[0] / 4), 4))
            lidar_data = np.array(points[:, :2])
            lidar_data *= min(self.hud.dim) / (2.0 * self.lidar_range)
            lidar_data += (0.5 * self.hud.dim[0], 0.5 * self.hud.dim[1])
            lidar_data = np.fabs(lidar_data)  # pylint: disable=E1111
            lidar_data = lidar_data.astype(np.int32)
            lidar_data = np.reshape(lidar_data, (-1, 2))
            lidar_img_size = (self.hud.dim[0], self.hud.dim[1], 3)
            lidar_img = np.zeros((lidar_img_size), dtype=np.uint8)
            lidar_img[tuple(lidar_data.T)] = (255, 255, 255)
            self.surface = pygame.surfarray.make_surface(lidar_img)
        elif self.sensors[self.index][0].startswith('sensor.camera.dvs'):
            # Example of converting the raw_data from a carla.DVSEventArray
            # sensor into a NumPy array and using it as an image
            dvs_events = np.frombuffer(image.raw_data, dtype=np.dtype([
                ('x', np.uint16), ('y', np.uint16), ('t', np.int64), ('pol', np.bool)]))
            dvs_img = np.zeros((image.height, image.width, 3), dtype=np.uint8)
            # Blue is positive, red is negative
            dvs_img[dvs_events[:]['y'], dvs_events[:]['x'], dvs_events[:]['pol'] * 2] = 255
            self.surface = pygame.surfarray.make_surface(dvs_img.swapaxes(0, 1))
        elif self.sensors[self.index][0].startswith('sensor.camera.optical_flow'):
            image = image.get_color_coded_flow()
            array = np.frombuffer(image.raw_data, dtype=np.dtype("uint8"))
            array = np.reshape(array, (image.height, image.width, 4))
            array = array[:, :, :3]
            array = array[:, :, ::-1]
            self.surface = pygame.surfarray.make_surface(array.swapaxes(0, 1))
        else:
            image.convert(self.sensors[self.index][1])
            array = np.frombuffer(image.raw_data, dtype=np.dtype("uint8"))
            array = np.reshape(array, (image.height, image.width, 4))
            array = array[:, :, :3]
            array = array[:, :, ::-1]
            self.surface = pygame.surfarray.make_surface(array.swapaxes(0, 1))
        if self.recording:
            image.save_to_disk('_out/%08d' % image.frame)
